"""
Search and query result data models for the RAG system.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from .document_chunk import DocumentChunk


@dataclass
class SearchResults:
    """
    Results from vector similarity search operations.
    
    Contains the indices, distances, and metadata for documents
    retrieved from the vector store.
    """
    indices: List[int]
    distances: List[float]
    metadata: List[Dict[str, Any]]
    
    def __post_init__(self):
        """Validate search results after initialization."""
        lengths = [len(self.indices), len(self.distances), len(self.metadata)]
        if not all(length == lengths[0] for length in lengths):
            raise ValueError("Indices, distances, and metadata must have the same length")
    
    def __len__(self) -> int:
        """Return the number of search results."""
        return len(self.indices)
    
    def is_empty(self) -> bool:
        """Check if the search results are empty."""
        return len(self.indices) == 0
    
    def get_top_k(self, k: int) -> 'SearchResults':
        """Get the top-k results."""
        k = min(k, len(self.indices))
        return SearchResults(
            indices=self.indices[:k],
            distances=self.distances[:k],
            metadata=self.metadata[:k]
        )


@dataclass
class QueryResults:
    """
    Results from processing a user query through the RAG pipeline.
    
    Contains the original query, retrieved document chunks, and relevance scores.
    """
    query: str
    retrieved_chunks: List[DocumentChunk]
    relevance_scores: List[float]
    total_results: int
    
    def __post_init__(self):
        """Validate query results after initialization."""
        if len(self.retrieved_chunks) != len(self.relevance_scores):
            raise ValueError("Retrieved chunks and relevance scores must have the same length")
        if not self.query.strip():
            raise ValueError("Query cannot be empty")
    
    def __len__(self) -> int:
        """Return the number of retrieved chunks."""
        return len(self.retrieved_chunks)
    
    def is_empty(self) -> bool:
        """Check if any results were retrieved."""
        return len(self.retrieved_chunks) == 0
    
    def get_sources(self) -> List[str]:
        """Get unique source files from retrieved chunks."""
        return list(set(chunk.source_file for chunk in self.retrieved_chunks))


@dataclass
class RetrievedContext:
    """
    Context retrieved and formatted for response generation.
    
    Contains the formatted context string, source chunks, and metadata
    for generating responses with proper attribution.
    """
    formatted_context: str
    source_chunks: List[DocumentChunk]
    total_tokens: int
    sources: List[str]
    
    def __post_init__(self):
        """Validate retrieved context after initialization."""
        if not self.formatted_context.strip():
            raise ValueError("Formatted context cannot be empty")
        if self.total_tokens < 0:
            raise ValueError("Total tokens cannot be negative")
    
    def is_empty(self) -> bool:
        """Check if the context is empty."""
        return not self.formatted_context.strip()
    
    def get_unique_sources(self) -> List[str]:
        """Get unique source files from the context."""
        return list(set(self.sources))


@dataclass
class GeneratedResponse:
    """
    Response generated by the LLM with context and attribution.
    
    Contains the response text, source attribution, confidence metrics,
    and metadata about the generation process.
    """
    response_text: str
    sources: List[str]
    confidence_score: float = 0.0
    context_used: bool = True
    token_count: int = 0
    model_used: str = ""
    generation_time: float = 0.0
    
    def __post_init__(self):
        """Validate generated response after initialization."""
        if not self.response_text.strip():
            raise ValueError("Response text cannot be empty")
        if not 0.0 <= self.confidence_score <= 1.0:
            raise ValueError("Confidence score must be between 0.0 and 1.0")
        if self.token_count < 0:
            raise ValueError("Token count cannot be negative")
        if self.generation_time < 0:
            raise ValueError("Generation time cannot be negative")
    
    def has_sources(self) -> bool:
        """Check if the response has source attribution."""
        return len(self.sources) > 0
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert the response to a dictionary for serialization."""
        return {
            "response_text": self.response_text,
            "sources": self.sources,
            "confidence_score": self.confidence_score,
            "context_used": self.context_used,
            "token_count": self.token_count,
            "model_used": self.model_used,
            "generation_time": self.generation_time
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'GeneratedResponse':
        """Create GeneratedResponse from a dictionary."""
        return cls(
            response_text=data["response_text"],
            sources=data.get("sources", []),
            confidence_score=data.get("confidence_score", 0.0),
            context_used=data.get("context_used", True),
            token_count=data.get("token_count", 0),
            model_used=data.get("model_used", ""),
            generation_time=data.get("generation_time", 0.0)
        )